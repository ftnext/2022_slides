機械学習を使った自然言語処理の例
============================================================

* タスク： **テキスト分類**
* ニュースグループの投稿をカテゴリに分類する

脱線：ニュースグループって？
--------------------------------------------------

* ネットニュースのグループ
* ネットニュース≒電子掲示板
* 「今で言うTwitterみたいなものね」

ニュースグループの投稿をカテゴリに分類
--------------------------------------------------

* scikit-learnのチュートリアル `Working With Text Data <https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html>`_

  * 機械学習アルゴリズムや評価用ツールが集まったライブラリ（📚[3] 1.3.2）

機械学習でモデルの訓練に必要なものは
--------------------------------------------------

* データ
* 機械学習アルゴリズム

.. revealjs-break::

* データ：ニュースグループの投稿（`sklearn.datasets.fetch_20newsgroups`）
* 機械学習アルゴリズム：サポートベクターマシン（`sklearn.svm.SVC`）

データから特徴量を抽出
--------------------------------------------------

* **テキストを数値に変換** して特徴量とする
* 投稿を数値を並べて表す

  * 今回は数値として単語の *TFIDF* を使うとする

TFIDFを使った特徴量のイメージ
--------------------------------------------------

* 全投稿に含まれる単語の数（約35000）だけ **数値を並べる**

  * 1つ1つの投稿は、35000個の数値の並びで表される（ベクトル）

.. revealjs-break::

* 投稿に含まれる単語はTFIDFの値、含まれない単語は0
* 例: `'OpenGL on the GPU is fast'`

.. code-block:: txt

    gpu god opengl  ... (35000語分並ぶ)
    0.67    0   0.60

TFIDFのイメージ
--------------------------------------------------

* TFIDFは正の小数（要裏とり）
* TFIDFが大きいほど、その投稿を *特徴づける* 単語（詳しくはAppendixへ TODO）

  * 先の例だと、openglやgpuはその投稿にしか現れないということ

モデルの気持ち
--------------------------------------------------

* このカテゴリは、これらの語のTFIDFが高いぞ！
* 別のカテゴリは、別の語たちのTFIDFが高いぞ！
* ただし、機械学習は、ルールを適用した結果、 **間違える可能性** がついて回ります

コード例
--------------------------------------------------

TODO includeして示す TfidfVectorizerなど（ファイルへのリンクも埋め込みたい）

英語と日本語の違い
--------------------------------------------------

* 英語は空白で単語が区切られている

  * そのまま `sklearn.feature_extraction.text.TfidfVectorizer` に入力できる

* 日本語ではまず単語を区切る必要がある（*分かち書き*）👉この後の例

もう一例：自然言語処理の例
============================================================

* タスク： **感情分析**
* この例では機械学習は登場しません（人手によるルール）

感情分析タスク
--------------------------------------------------

* 文書がポジティブかネガティブかを判定
* 極性判定とも言われる
* 機械学習の **二値分類** （2つのカテゴリに分類）

ポジティブ／ネガティブな単語を数える 📚[3] 5.2.5
--------------------------------------------------

* **人手** によるルールでアプローチ！
* あくまで📚[3]流で、他のやり方もありえます（例：教師あり学習として解く）

『吾輩は猫である』を感情分析
--------------------------------------------------

.. code-block:: txt

    吾輩は猫である。
    名前はまだ無い。
    どこで生れたかとんと見当がつかぬ。

文で区切られたテキストがあるとします（用意する過程はAppendix）

『吾猫』のポジティブ／ネガティブな単語を数える
--------------------------------------------------

1. 単語を数える前に、単語に分ける
2. ポジティブな単語・ネガティブな単語を一覧にする
3. 単語を数えて感情分析

(1) **分かち書き** して単語に分ける
--------------------------------------------------

* 文を構成する単語を取り出す
* 日本語のように、単語が区切られていない言語の処理で必要

分かち書きの例
--------------------------------------------------

.. code-block:: txt

    吾輩/は/猫/で/ある/。
    名前/は/まだ/無い/。
    どこ/で/生れ/た/か/と/んと/見当/が/つか/ぬ/。

fugashi (MeCab) + unidic の結果

分かち書きに使うPythonライブラリ
--------------------------------------------------

* 形態素解析エンジンMeCabのラッパーライブラリ
* MeCabを使うと **単語分割と品詞付与** できる
* fugashiでMeCabをPythonから使う

形態素解析＝単語分割＋品詞付与（📚[1] 2-5）
--------------------------------------------------

* 単語分割＝分かち書き
* 品詞：名詞、動詞など（下にイメージ）

.. code-block:: txt

    やばい	形容詞,自立,*,*,形容詞・アウオ段,基本形,やばい,ヤバイ,ヤバイ

(1') 単語を原形に揃える
--------------------------------------------------

* 文中の単語は活用されている（例：ウケた）
* 原形＝活用前の形式＝辞書に載っている（例：ウケる）
* 用意する一覧（後述）で、原形だけを利用する都合による

原形に揃える例
--------------------------------------------------

.. code-block:: txt

    我が輩/は/猫/だ/有る/。
    名前/は/未だ/無い/。
    何処/で/生まれる/た/か/と/うんと/見当/が/付く/ず/。

fugashi (MeCab) + unidic の結果

(2) 日本語極性評価辞書
--------------------------------------------------

* ポジティブな単語、ネガティブな単語の一覧
* https://www.cl.ecei.tohoku.ac.jp/Open_Resources-Japanese_Sentiment_Polarity_Dictionary.html から入手可能
* **tsvファイル** として読み込む（Pythonのcsvモジュール）

(3) ポジティブ／ネガティブな単語を数える
--------------------------------------------------

* 文書の極性＝単語の極性の総和

  * ポジティブな単語があれば+1
  * ネガティブな単語があれば-1
  * （極性辞書にない単語は何もしない）

『吾輩は猫である』の感情分析結果
--------------------------------------------------

TODO 極端な例を表示


TODO まとめを入れる
