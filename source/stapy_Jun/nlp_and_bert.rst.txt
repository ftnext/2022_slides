Part II. 自然言語処理とBERT
============================================================

最近の自然言語処理を席巻しているBERTがいよいよ登場します

ニューラル言語モデル
============================================================

* ニューラルネットワーク により実現される
* 言語モデル

ニューラルネットワーク（📚[2] 2-2）
--------------------------------------------------

* 機械学習アルゴリズムの1つ
* 変換を行う層を（何層も）組合せる

.. あたらしいデータ分析の教科書

言語モデル（📚[2] 2-1）
--------------------------------------------------

* 文章の出現しやすさを確率によってモデル化

  * 「私はパンを食べた」>「私はパンに食べた」>「私は家を食べた」

* この確率は文章の自然さとも見なせる

ニューラル言語モデルの訓練
--------------------------------------------------

* 言語モデルとなるニューラルネットワークを訓練する
* 自然言語からラベル付きデータを自動で作れる

  * 例：それまでの単語たちから次の単語を予測

ニューラルネットワークへの入力
--------------------------------------------------

* 単語を **整数ID** に変換だけして入力
* 各単語（ID）をどのようなベクトルとして扱うかも自動で見つける

.. TODO 整数IDの例

用語紹介「深層学習」（📚[2] 1-3）
--------------------------------------------------

* 1つのモデルで特徴量抽出とその後の処理を行う
* 人手によらない特徴量抽出
* 特徴量の抽出も含めて、データからルールを自動で見つける

BERT
============================================================

Transformer（📚[2] 3-1）
--------------------------------------------------

* 2017年の論文「Attention is All You Need」で提案されたモデル
* BERTはTransformerで提案されたニューラルネットワークを用いる

BERT
--------------------------------------------------

* 2018年発表
* Bidirectional Encoder Representations from Transformersの略
* **1つのモデルで複数のタスクを扱える** のが革新的

.. コンビニの例

ライブラリ `transformers`
--------------------------------------------------

* Transformerやそれ以後に派生したモデルを扱うためのライブラリ
* Transformerモデルの訓練や、読み込んで推論をサポート
* もちろんBERTもサポート

BERTの利用例：感情分析タスク
============================================================

先の『吾輩は猫である』の例（文書の二値分類）をBERTでやってやりましょう

コードはこれだけ！
--------------------------------------------------

TODO 埋め込む、または、ここに書く

BERTによる感情分析結果
--------------------------------------------------

.. code-block:: txt

    吾輩は猫である。
    -> [{'label': 'ポジティブ', 'score': 0.9909781217575073}]

    名前はまだ無い。
    -> [{'label': 'ポジティブ', 'score': 0.5273743867874146}]
    （ネガティブが0.47なので、自信がない）

    どこで生れたかとんと見当がつかぬ。
    -> [{'label': 'ネガティブ', 'score': 0.9475129842758179}]

コードの裏で行われていること
--------------------------------------------------

* 日本語の感情分析BERTのファイルをダウンロード
* モデルとトークナイザをファイルを読み込む

.. TODO（ファイルを示したい）

トークナイザとは
--------------------------------------------------

* 「単語どうしを区切る」役割
* ただし、単語（word）よりも細かい単位（**サブワード**）で区切ることがある

.. code-block:: python

    >>> nlp.tokenizer.encode("吾輩は猫である。")  # トークナイザによりIDの並び
    [2, 7184, 30046, 9, 6040, 12, 31, 8, 3]
    >>> # decodeすると 吾輩/は/猫/で/ある/。 と分かち書きされた

.. 得内座👹「お前もTransformer使いにならないか」
