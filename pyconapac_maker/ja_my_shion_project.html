
<!DOCTYPE html>

<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <title>[ãƒ‰ãƒ©ãƒ•ãƒˆç‰ˆ] Pythonã§å®Ÿè£…ã™ã‚‹ã€ã€ã‚¢ã‚¤ã®æ­Œå£°ã‚’è´ã‹ã›ã¦ã€ã®è©©éŸ³</title>
    <link rel="stylesheet" type="text/css" href="../_static/revealjs4/dist/reveal.css" />
    <link rel="stylesheet" href="../_static/revealjs4/dist/theme/black.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/revealjs4/plugin/highlight/zenburn.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/common.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/translations.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../genindex.html" />
    <link rel="search" title="æ¤œç´¢" href="../search.html" />
    
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    
    


    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@ftnext">
    <meta property="og:url" content="https://ftnext.github.io/2022_slides//.html">
    <meta property="og:title" content="">
    <meta property="og:description" content="">
    <meta property="og:image" content="https://ftnext.github.io/2022_slides/_static/ogps/.png">

  </head><body>
    <div class="reveal">
        <div class="slides">
            <section >
<h1>[ãƒ‰ãƒ©ãƒ•ãƒˆç‰ˆ] Pythonã§å®Ÿè£…ã™ã‚‹ã€ã€ã‚¢ã‚¤ã®æ­Œå£°ã‚’è´ã‹ã›ã¦ã€ã®è©©éŸ³</h1>
<dl class="field-list simple">
<dt class="field-odd">Event<span class="colon">:</span></dt>
<dd class="field-odd"><p>PyCon APAC 2022</p>
</dd>
<dt class="field-even">Presented<span class="colon">:</span></dt>
<dd class="field-even"><p>2022/07/20 (pre-recorded) nikkie</p>
</dd>
</dl>
</section>
<section>
<section >
<h2>ãŠå‰ã€èª°ã‚ˆ</h2>
<ul class="simple">
<li><p>Pythonï¼ˆã¨ã‚¢ãƒ‹ãƒ¡ï¼‰å¤§å¥½ã <strong>ã«ã£ããƒ¼</strong> ï¼ Twitter <a class="reference external" href="https://twitter.com/ftnext">&#64;ftnext</a> ï¼ GitHub <a class="reference external" href="https://github.com/ftnext">&#64;ftnext</a></p></li>
<li><p>ã‚¢ãƒ‹ãƒ¡ x PythonãŒé«˜ã˜ã¦ä»Šå›è©±ã—ã¾ã™</p></li>
<li><p>PyCon JP 2019ã€œ2020 ã‚¹ã‚¿ãƒƒãƒ• ï¼ 2021 åº§é•·</p></li>
</ul>
</section>
<section >
<h2>ãŠå‰ã€èª°ã‚ˆ</h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.uzabase.com/jp/">æ ªå¼ä¼šç¤¾ãƒ¦ãƒ¼ã‚¶ãƒ™ãƒ¼ã‚¹</a> ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ</p></li>
<li><p>We're hiring!! (Engineers, Data scientists, Researchers)</p></li>
</ul>
</section>
<section >
<h3>Revisit Python from statements and PEGã‚‚è©±ã—ã¾ã™</h3>
<aside class="notes">
TODO ã‚¹ãƒ©ã‚¤ãƒ‰åŸ‹ã‚è¾¼ã¿</aside>
</section>
</section>
<section>
<section >
<h2>ã‚¢ã‚¤ã®æ­Œå£°ã‚’è´ã‹ã›ã¦</h2>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/9h8NqlENtI0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></section>
<section >
<h2>ã‚¢ã‚¤ã®æ­Œå£°ã‚’è´ã‹ã›ã¦</h2>
<ul class="simple">
<li><p>2021/10æ—¥æœ¬ã§å…¬é–‹ã•ã‚ŒãŸã‚¢ãƒ‹ãƒ¡ <strong>æ˜ ç”»</strong></p></li>
<li><p>SF x ã‚¸ãƒ¥ãƒ–ãƒŠã‚¤ãƒ« x ãƒŸãƒ¥ãƒ¼ã‚¸ã‚«ãƒ«</p></li>
<li><p>éµã¨ãªã‚‹ã‚­ãƒ£ãƒ©ã¯ã€ <strong>AIãƒ­ãƒœãƒƒãƒˆ</strong> ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ï¼‰ã® <strong>è©©éŸ³</strong></p></li>
</ul>
</section>
<section >
<h3>äºˆå‘Šã®å†’é ­ è©©éŸ³ã€Œç§ãŒå¹¸ã›ã«ã—ã¦ã‚ã’ã‚‹ï¼ã€</h3>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/1UeIEUoHZ6E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>è©©éŸ³ã‚’å®Ÿè£…ã—ãŸã„ï¼ï¼</p>
</section>
<section >
<h3>ã“ã®ãƒˆãƒ¼ã‚¯ã§ã¯</h3>
<ul class="simple">
<li><p>ç§ã®ãƒ¡ã‚¤ã‚«ãƒ¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€ŒPythonã§è©©éŸ³ã‚’å®Ÿè£…ã€ã‚’å…±æœ‰ã—ã¾ã™</p></li>
<li><p>ã‚ãªãŸã®ãƒ¡ã‚¤ã‚«ãƒ¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å°ã•ãã¦ã‚‚ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚Œã°å¬‰ã—ã„ã§ã™</p></li>
</ul>
</section>
<section >
<h3>ãŠã“ã¨ã‚ã‚Š</h3>
<ul class="simple">
<li><p>è©©éŸ³ã«ã¤ã„ã¦ã¯åŠ‡ä¸­ã«OSã‚„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«ã¤ã„ã¦ã®è¨˜è¼‰ã¯ãªã„ã¨æ€ã„ã¾ã™ã€‚ã¤ã¾ã‚Šã€ã“ã“ã§å…±æœ‰ã™ã‚‹å®Ÿè£…ã¯nikkieï¼ˆä¸€ãƒ•ã‚¡ãƒ³ï¼‰ã® <strong>å¦„æƒ³</strong> ã§ã™</p></li>
<li><p>éŸ³å£°ã‚’æ‰±ã£ã¦ã„ãã¾ã™ãŒã€nikkieè‡ªèº«ã¯éŸ³å£°ã®å°‚é–€å®¶ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆç‹¬å­¦ã§ã™ã®ã§ã€ã‚ˆã‚Šã‚ˆã„æ–¹æ³•ãŒã‚ã£ãŸã‚‰ãœã²æ•™ãˆã¦ãã ã•ã„ï¼ï¼‰</p></li>
</ul>
</section>
</section>
<section>
<section >
<h2>Pythonã§è©©éŸ³ã‚’å®Ÿè£…ã™ã‚‹</h2>
<ul class="simple">
<li><p>è©©éŸ³ã®ã€Œäººã¨è©±ã›ã‚‹ã€æ©Ÿèƒ½ã‚’å®Ÿè£…ã™ã‚‹</p></li>
<li><p>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã ã‘å®Ÿè£…ã™ã‚‹</p></li>
<li><p>å°ã•ãå§‹ã‚ã‚‹</p></li>
</ul>
</section>
<section >
<h3>è©©éŸ³ v0.0.1 ã®å®šç¾©</h3>
<ul class="simple">
<li><p>äººã¨è©±ã›ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ </p></li>
<li><p>ã‚¹ãƒãƒ¼ãƒˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®ã‚ˆã†ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ </p></li>
</ul>
</section>
<section >
<h3>ãƒ‡ãƒ¢ï¼šè©©éŸ³ v0.0.1</h3>
<ul class="simple">
<li><p>è©±ã—ãŸè¨€è‘‰ã‚’ã‚ªã‚¦ãƒ è¿”ã—</p>
<ul>
<li><p>ã“ã‚“ã«ã¡ã¯</p></li>
<li><p>ã„ã„ï¼Ÿ å‘½ä»¤ã™ã‚‹ã‚ˆï¼Ÿ</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section>
<section >
<h2>æŠ€è¡“è¦ä»¶ã®æ•´ç†</h2>
<p>è©©éŸ³ v0.0.1 ã‚’æ”¯ãˆã‚‹æŠ€è¡“</p>
</section>
<section >
<h3>è©©éŸ³ v0.0.1 ã®å®šç¾©</h3>
<p>äººãŒéŸ³å£°ã§å…¥åŠ›</p>
<ol class="arabic simple">
<li><p>éŸ³å£°ã‚’èªè­˜ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹</p></li>
<li><p>ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦å¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œã‚‹</p></li>
<li><p>å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ä¸Šã’ã‚‹</p></li>
</ol>
</section>
<section >
<h3>ä¸»è¦ãªæŠ€è¡“è¦ç´ </h3>
<ul class="simple">
<li><p>å…¥åŠ›ï¼šéŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›</p></li>
<li><p>å‡ºåŠ›ï¼šãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ä¸Šã’</p></li>
<li><p>æœ¬ãƒˆãƒ¼ã‚¯ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†ã¯å˜ç´”ãªã‚ªã‚¦ãƒ è¿”ã—</p></li>
</ul>
</section>
<section >
<h3>æ¤œè¨¼ã¨ä½œã‚Šè¾¼ã¿</h3>
<ul class="simple">
<li><p>è©©éŸ³ã®å®Ÿè£…ã«ç´å¾—ã§ãã‚‹ã‹ã¯ä½œã£ã¦ã¿ãªã„ã¨åˆ†ã‹ã‚‰ãªã„</p></li>
<li><p>åˆæ‰‹ï¼šæ‰‹æ—©ãã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æ¤œè¨¼ã™ã‚‹ã“ã¨ã‚’å„ªå…ˆ</p></li>
<li><p>ã‚ˆã•ãã†ã§ã‚ã‚Œã°ã€åŠ‡ä¸­ã®è©©éŸ³ã«è¿‘ã¥ã‘ã‚‹</p></li>
</ul>
</section>
</section>
<section>
<section >
<h2>ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ä¸Šã’ã‚‹æŠ€è¡“</h2>
<ul class="simple">
<li><p><strong>éŸ³å£°åˆæˆ</strong> ã¨å‘¼ã°ã‚Œã‚‹</p></li>
<li><p>Text-To-Speechï¼ˆ<strong>TTS</strong>ï¼‰</p></li>
</ul>
</section>
<section >
<h3>ã“ã®ãƒˆãƒ¼ã‚¯ã§ç´¹ä»‹ã™ã‚‹éŸ³å£°åˆæˆ</h3>
<ul class="simple">
<li><p>åˆæ‰‹ï¼šOSã‚³ãƒãƒ³ãƒ‰å‘¼ã³å‡ºã—</p></li>
<li><p>ã‚ˆã‚Šæœ¬æ ¼çš„ã«ï¼šæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«</p></li>
</ul>
</section>
</section>
<section>
<section >
<h2>éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰ãˆã‚‹æŠ€è¡“</h2>
<ul class="simple">
<li><p><strong>éŸ³å£°èªè­˜</strong> ã¨å‘¼ã°ã‚Œã‚‹</p></li>
<li><p>Automatic Speech Recognitionï¼ˆ<strong>ASR</strong>ï¼‰</p></li>
</ul>
</section>
<section >
<h3>ã“ã®ãƒˆãƒ¼ã‚¯ã§ç´¹ä»‹ã™ã‚‹éŸ³å£°åˆæˆ</h3>
<ul class="simple">
<li><p>åˆæ‰‹ï¼šWeb APIåˆ©ç”¨</p></li>
<li><p>ã‚ˆã‚Šæœ¬æ ¼çš„ã«ï¼šæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«</p></li>
</ul>
</section>
<section >
<h3>ç´¹ä»‹ã™ã‚‹æŠ€è¡“ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—</h3>
<ul class="simple">
<li><p><strong>TTS åˆæ‰‹</strong></p></li>
<li><p>ASR åˆæ‰‹</p></li>
<li><p>TTS ä½œã‚Šè¾¼ã¿</p></li>
<li><p>ASR ä½œã‚Šè¾¼ã¿</p></li>
</ul>
</section>
</section>
<section>
<section >
<h2>TTS åˆæ‰‹ï¼šOSã‚³ãƒãƒ³ãƒ‰å‘¼ã³å‡ºã—</h2>
</section>
<section >
<h3>TTSï¼ˆéŸ³å£°åˆæˆï¼‰ã‚³ãƒãƒ³ãƒ‰</h3>
<ul class="simple">
<li><p>macOS: <strong class="command">say</strong> ã‚³ãƒãƒ³ãƒ‰ï¼ˆã“ã®å¾Œè©³ã—ãï¼‰</p></li>
<li><p>Linuxã‚„Windows: <a class="reference external" href="http://espeak.sourceforge.net/">espeak ã‚³ãƒãƒ³ãƒ‰</a></p></li>
</ul>
</section>
<section >
<h3>macOSã® <code class="docutils literal notranslate"><span class="pre">say</span></code> ã‚³ãƒãƒ³ãƒ‰</h3>
<pre data-id="macos-say"><code data-trim data-noescape class="shell">say -v Kyoko ã„ã¾ã€å¹¸ã›ï¼Ÿ</code></pre>
<ul class="simple">
<li><p><strong class="command">say -v ?</strong> ã§è¨€èªã”ã¨ã®voiceã‚’ä¸€è¦§ã§ãã‚‹</p>
<ul>
<li><p>ja_JP: Kyoko</p></li>
<li><p>zh_TW: Mei-Jia</p></li>
</ul>
</li>
</ul>
<aside class="notes">
zh-TW is an IETF language tag for the Chinese language as used in Taiwan,
https://en.wikipedia.org/wiki/Zh-TW</aside>
</section>
<section >
<h3>sayã‚³ãƒãƒ³ãƒ‰ã‚’Pythonã‹ã‚‰å‘¼ã³å‡ºã™</h3>
<ul class="simple">
<li><p>æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã® <code class="docutils literal notranslate"><span class="pre">subprocess</span></code></p></li>
<li><p>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸­ã®ä¾‹ã€Œ<a class="reference external" href="https://docs.python.org/ja/3/howto/logging-cookbook.html#speaking-logging-messages">ãƒ­ã‚®ãƒ³ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–‹ã‚‹</a>ã€</p></li>
</ul>
</section>
<section >
<h3><code class="docutils literal notranslate"><span class="pre">subprocess.run</span></code></h3>
<ul class="simple">
<li><p>TTSã«é™ã‚‰ãšã‚³ãƒãƒ³ãƒ‰ã‚’å‘¼ã³å‡ºã›ã‚‹</p></li>
<li><p>ã‚³ãƒãƒ³ãƒ‰ã¯ <strong>å¼•æ•°ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹</strong> ã¨ã—ã¦æ¸¡ã™</p></li>
</ul>
<pre data-id="subprocess-run"><code data-trim data-noescape class="python">&gt;&gt;&gt; import subprocess
&gt;&gt;&gt; subprocess.run([&quot;ls&quot;, &quot;-l&quot;])  # ls -l ã‚’å‘¼ã³å‡ºã™</code></pre>
<aside class="notes">
ã€Œä¸€èˆ¬ã«ã€å¼•æ•°ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’æ¸¡ã™æ–¹ãŒæœ›ã¾ã—ã„ã§ã™ã€‚ã€
https://docs.python.org/ja/3/library/subprocess.html#frequently-used-arguments</aside>
</section>
<section >
<h3><code class="docutils literal notranslate"><span class="pre">subprocess.run</span></code> ã‚’ä½¿ã£ãŸTTS</h3>
<pre data-id="subprocess-run-tts"><code data-trim data-noescape class="python">&gt;&gt;&gt; import subprocess
&gt;&gt;&gt; subprocess.run([&quot;say&quot;, &quot;-v&quot;, &quot;Kyoko&quot;, &quot;ã„ã¾ã€å¹¸ã›ï¼Ÿ&quot;])</code></pre>
</section>
<section >
<h3>TTSã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ</h3>
<pre data-id="id19"><code data-trim data-noescape class="python" data-line-numbers="6">import readline  # noqa: F401
import subprocess


def say(sentence: str):
    subprocess.run([&quot;say&quot;, &quot;-v&quot;, &quot;Kyoko&quot;, sentence])


if __name__ == &quot;__main__&quot;:
    while True:
        sentence = input(&quot;èª­ã¿ä¸Šã’ãŸã„æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (qã§çµ‚äº†): &quot;)
        stripped = sentence.strip()
        if not stripped:
            continue
        if stripped.lower() == &quot;q&quot;:
            break

        say(stripped)
</code></pre>
</section>
<section >
<h3>ç´¹ä»‹ã™ã‚‹æŠ€è¡“ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—</h3>
<ul class="simple">
<li><p>TTS åˆæ‰‹</p></li>
<li><p><strong>ASR åˆæ‰‹</strong></p></li>
<li><p>TTS ä½œã‚Šè¾¼ã¿</p></li>
<li><p>ASR ä½œã‚Šè¾¼ã¿</p></li>
</ul>
</section>
</section>
<section>
<section >
<h2>ASR åˆæ‰‹ï¼šWeb APIåˆ©ç”¨</h2>
</section>
<section >
<h3>ASRï¼ˆéŸ³å£°èªè­˜ï¼‰Web API</h3>
<ul class="simple">
<li><p>Google Cloud Speech-to-Text APIï¼ˆğŸ‘ˆä»Šå›åˆ©ç”¨ï¼‰</p></li>
<li><p>Microsoft Azure Speech</p></li>
<li><p>IBM Speech to Text</p></li>
<li><p>etc. etc.</p></li>
</ul>
</section>
<section >
<h3>ãƒ©ã‚¤ãƒ–ãƒ©ãƒª <code class="docutils literal notranslate"><span class="pre">SpeechRecognition</span></code></h3>
<ul class="simple">
<li><p>éŸ³å£°èªè­˜ï¼ˆASRï¼‰ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p></li>
<li><p>Web APIã‚„ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ã‚µãƒãƒ¼ãƒˆ</p></li>
<li><p><a class="reference external" href="https://github.com/Uberi/speech_recognition">https://github.com/Uberi/speech_recognition</a></p></li>
</ul>
</section>
<section >
<h3><code class="docutils literal notranslate"><span class="pre">SpeechRecognition</span></code> ã‚’ä½¿ã£ã¦å®Ÿè£…ã™ã‚‹å‡¦ç†</h3>
<ol class="arabic simple">
<li><p>ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’å–å¾—</p></li>
<li><p>éŸ³å£°ã‚’ASR Web APIã«é€ã‚‹</p></li>
</ol>
</section>
<section >
<h3>1.ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’å–å¾—</h3>
<pre data-id="id23"><code data-trim data-noescape class="python">&gt;&gt;&gt; import speech_recognition as sr
&gt;&gt;&gt; r = sr.Recognizer()
&gt;&gt;&gt; with sr.Microphone(sample_rate=16_000) as source:
...     print(&quot;ãªã«ã‹è©±ã—ã¦ãã ã•ã„&quot;)
...     audio = r.listen(source)
...     print(&quot;éŸ³å£°ã‚’å–å¾—ã—ã¾ã—ãŸ&quot;)</code></pre>
</section>
<section >
<h3>2.éŸ³å£°ã‚’ASR Web APIã«é€ã‚‹</h3>
<p>Google Cloud Speech-to-Text APIã‚’åˆ©ç”¨</p>
<pre data-id="id24"><code data-trim data-noescape class="python">&gt;&gt;&gt; with open(&quot;path/to/service_account_key.json&quot;) as f:
...     credentials = f.read()
&gt;&gt;&gt; recognized_text = r.recognize_google_cloud(
...     audio, credentials, language=&quot;ja-JP&quot;
... )
&gt;&gt;&gt; print(recognized_text.strip())</code></pre>
</section>
<section >
<h3>ASRã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ</h3>
<pre data-id="asr"><code data-trim data-noescape class="python" data-line-numbers="9,17,18,19,28,29,30,31">import argparse

import speech_recognition as sr


def input_from_microphone(recognizer: &quot;sr.Recognizer&quot;) -&gt; &quot;sr.AudioData&quot;:
    with sr.Microphone(sample_rate=16_000) as source:
        print(&quot;ãªã«ã‹è©±ã—ã¦ãã ã•ã„&quot;)
        audio = recognizer.listen(source)
        print(&quot;éŸ³å£°ã‚’å–å¾—ã—ã¾ã—ãŸ&quot;)
        return audio


def recognize_speech(
    recognizer: &quot;sr.Recognizer&quot;, audio: &quot;sr.AudioData&quot;, credentials: str
) -&gt; str:
    recognized_text = recognizer.recognize_google_cloud(
        audio, credentials, language=&quot;ja-JP&quot;
    )
    return recognized_text.strip()


if __name__ == &quot;__main__&quot;:
    parser = argparse.ArgumentParser()
    parser.add_argument(&quot;credentials_path&quot;)
    args = parser.parse_args()

    with open(args.credentials_path) as f:
        credentials = f.read()

    r = sr.Recognizer()

    while True:
        audio = input_from_microphone(r)
        text = recognize_speech(r, audio, credentials)
        print(text)

        character = input(&quot;ã“ã“ã§çµ‚äº†ã™ã‚‹å ´åˆã¯qã€ç¶šã‘ã‚‹å ´åˆã¯Enterã‚’æŠ¼ã—ã¦ãã ã•ã„: &quot;)
        if character.strip().lower() == &quot;q&quot;:
            break
</code></pre>
</section>
</section>
<section>
<section >
<h2>è©©éŸ³ã‚’ä½œã‚ŠãŸã„ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å®Ÿè£…</h2>
<ul class="simple">
<li><p><strong>æ‰‹æ—©ã</strong> ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ <strong>æ¤œè¨¼</strong> ã™ã‚‹ã“ã¨ã‚’å„ªå…ˆ</p></li>
<li><p>TTS: <code class="docutils literal notranslate"><span class="pre">subprocess.run</span></code></p></li>
<li><p>ASR: Web API</p></li>
</ul>
</section>
<section >
<h3>æ¤œè¨¼çµæœ</h3>
<ul class="simple">
<li><p>LGTMğŸ‘ï¼ˆé–‹ç™ºè€…ã®å®šæ€§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼‰</p></li>
<li><p>ã‚‚ã£ã¨è©©éŸ³ã«è¿‘ã¥ã‘ãŸã„ï¼</p></li>
</ul>
</section>
<section >
<h3>æ‰‹æ—©ã„å®Ÿè£…ã®ä¼¸ã³ã—ã‚1</h3>
<ul class="simple">
<li><p><strong class="command">say</strong> ã‚³ãƒãƒ³ãƒ‰ã¯OSä¾å­˜</p></li>
<li><p>è©©éŸ³ã¯macOSã§ã¯å‹•ã„ã¦ã„ãªã•ãã†</p></li>
</ul>
</section>
<section >
<h3>æ‰‹æ—©ã„å®Ÿè£…ã®ä¼¸ã³ã—ã‚2</h3>
<ul class="simple">
<li><p>Web APIã®åˆ©ç”¨ã¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ã«ä¾å­˜</p></li>
<li><p>è©©éŸ³ã¯ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ¼ãƒ³ï¼Web APIã¨é€šä¿¡ã—ãªã„</p></li>
</ul>
</section>
<section >
<h3>ã‚‚ã£ã¨è©©éŸ³ã«è¿‘ã¥ã‘ã‚‹ï¼</h3>
<ul class="simple">
<li><p>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</p></li>
<li><p>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§TTS &amp; ASR</p></li>
</ul>
</section>
<section >
<h3>ç´¹ä»‹ã™ã‚‹æŠ€è¡“ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—</h3>
<ul class="simple">
<li><p>TTS åˆæ‰‹</p></li>
<li><p>ASR åˆæ‰‹</p></li>
<li><p><em>TTS ä½œã‚Šè¾¼ã¿</em></p></li>
<li><p><em>ASR ä½œã‚Šè¾¼ã¿</em></p></li>
</ul>
</section>
</section>
<section>
<section >
<h2>TTS ä½œã‚Šè¾¼ã¿ï¼šæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨</h2>
</section>
<section >
<h3>ãƒ©ã‚¤ãƒ–ãƒ©ãƒª <code class="docutils literal notranslate"><span class="pre">ttslearn</span></code></h3>
<ul class="simple">
<li><p>éŸ³å£°åˆæˆï¼ˆTTSï¼‰ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆ<strong>æ—¥æœ¬èª</strong> å¯¾å¿œï¼‰</p></li>
<li><p>ã€Pythonã§å­¦ã¶éŸ³å£°åˆæˆã€</p></li>
<li><p><a class="reference external" href="https://github.com/r9y9/ttslearn">https://github.com/r9y9/ttslearn</a></p></li>
</ul>
</section>
<section >
<h3>æ—¥æœ¬èªéŸ³å£°åˆæˆã®ã‚³ãƒ¼ãƒ‰ä¾‹</h3>
<pre data-id="id32"><code data-trim data-noescape class="python">&gt;&gt;&gt; from ttslearn.dnntts import DNNTTS
&gt;&gt;&gt; dnntts_engine = DNNTTS()
&gt;&gt;&gt; audio_array, sampling_rate = dnntts_engine.tts(&quot;ã„ã¾ã€å¹¸ã›ï¼Ÿ&quot;)</code></pre>
</section>
<section >
<h3><code class="docutils literal notranslate"><span class="pre">DNNTTS()</span></code></h3>
<ul class="simple">
<li><p>æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆDNNï¼‰ã‚’ä½¿ã£ãŸéŸ³å£°åˆæˆã®å®Ÿè£…</p></li>
<li><p>äº‹å‰è¨“ç·´æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ï¼‰èª­ã¿è¾¼ã‚“ã§ã„ã‚‹</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tts</span></code> ãƒ¡ã‚½ãƒƒãƒ‰ã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ã™ <strong>NumPy array</strong> ãŒè¿”ã‚‹</p></li>
</ul>
</section>
<section >
<h3>åˆæˆéŸ³å£°ã®å†ç”Ÿ <code class="docutils literal notranslate"><span class="pre">sounddevice</span></code></h3>
<ul class="simple">
<li><p>Pythonã§éŸ³å£°ã‚’å†ç”Ÿãƒ»éŒ²éŸ³ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p></li>
<li><p>éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ã™ <strong>NumPy arrayã‚’å†ç”Ÿ</strong> ã™ã‚‹ã®ã«ä½¿ã†</p></li>
<li><p><a class="reference external" href="https://github.com/spatialaudio/python-sounddevice/">https://github.com/spatialaudio/python-sounddevice/</a></p></li>
</ul>
</section>
<section >
<h3>TTSã®ã‚³ãƒ¼ãƒ‰ä¾‹</h3>
<pre data-id="id33"><code data-trim data-noescape class="python">&gt;&gt;&gt; audio_array, sampling_rate = dnntts_engine.tts(&quot;ã„ã¾ã€å¹¸ã›ï¼Ÿ&quot;)
&gt;&gt;&gt; import sounddevice as sd
&gt;&gt;&gt; sd.play(audio_array, sampling_rate)
&gt;&gt;&gt; sd.wait()</code></pre>
</section>
<section >
<h3>ä½œã‚Šè¾¼ã‚“ã TTSã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ</h3>
<pre data-id="id34"><code data-trim data-noescape class="python" data-line-numbers="6,10,11,12">import readline  # noqa: F401

import sounddevice as sd
from ttslearn.dnntts import DNNTTS

dnntts_engine = DNNTTS()


def say(sentence: str):
    audio_array, sampling_rate = dnntts_engine.tts(sentence)
    sd.play(audio_array, sampling_rate)
    sd.wait()


if __name__ == &quot;__main__&quot;:
    while True:
        sentence = input(&quot;èª­ã¿ä¸Šã’ãŸã„æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (qã§çµ‚äº†): &quot;)
        stripped = sentence.strip()
        if not stripped:
            continue
        if stripped.lower() == &quot;q&quot;:
            break

        say(stripped)
</code></pre>
</section>
<section >
<h3>ç´¹ä»‹ã™ã‚‹æŠ€è¡“ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—</h3>
<ul class="simple">
<li><p>TTS åˆæ‰‹</p></li>
<li><p>ASR åˆæ‰‹</p></li>
<li><p>TTS ä½œã‚Šè¾¼ã¿</p></li>
<li><p><strong>ASR ä½œã‚Šè¾¼ã¿</strong></p></li>
</ul>
</section>
</section>
<section>
<section >
<h2>ASR ä½œã‚Šè¾¼ã¿ï¼šæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨</h2>
</section>
<section >
<h3>ãƒ©ã‚¤ãƒ–ãƒ©ãƒª <code class="docutils literal notranslate"><span class="pre">ESPnet</span></code></h3>
<ul class="simple">
<li><p>ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®éŸ³å£°å‡¦ç†ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ</p></li>
<li><p><strong>éŸ³å£°èªè­˜ï¼ˆASRï¼‰ã‚’åˆ©ç”¨</strong> ï¼ˆTTSã‚‚ã‚µãƒãƒ¼ãƒˆï¼‰</p></li>
<li><p><a class="reference external" href="https://github.com/espnet/espnet">https://github.com/espnet/espnet</a></p></li>
</ul>
</section>
<section >
<h3>äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨</h3>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/espnet/kan-bayashi_csj_asr_train_asr_transformer_raw_char_sp_valid.acc.ave">Hugging Faceã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«</a> ã‚’åˆ©ç”¨</p>
<ul>
<li><p>ä½œæˆè€…ã«ã‚ˆã‚Š <strong>äº‹å‰è¨“ç·´æ¸ˆã¿</strong> ï¼ˆpre-trainedï¼‰</p></li>
</ul>
</li>
<li><p><strong class="command">pip install espnet-model-zoo</strong></p></li>
</ul>
</section>
<section >
<h3>äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹</h3>
<pre data-id="id38"><code data-trim data-noescape class="python">&gt;&gt;&gt; from espnet2.bin.asr_inference import Speech2Text
&gt;&gt;&gt; speech2text = Speech2Text.from_pretrained(
...     &quot;kan-bayashi/csj_asr_train_asr_transformer_raw_char_sp_valid.acc.ave&quot;
... )</code></pre>
</section>
<section >
<h3>Espnetã®äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ASRä½œã‚Šè¾¼ã¿</h3>
<ol class="arabic simple">
<li><p>First step: wavãƒ•ã‚¡ã‚¤ãƒ«ã®ASR</p></li>
<li><p>ãƒã‚¤ã‚¯ã‹ã‚‰å…¥åŠ›ã—ãŸéŸ³å£°ã®ASR</p></li>
</ol>
</section>
</section>
<section>
<section >
<h2>First step: wavãƒ•ã‚¡ã‚¤ãƒ«ã®ASR</h2>
</section>
<section >
<h3>ãƒ©ã‚¤ãƒ–ãƒ©ãƒª <code class="docutils literal notranslate"><span class="pre">SoundFile</span></code></h3>
<ul>
<li><p>éŸ³å£°ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p>
<blockquote>
<div><p>an audio library based on libsndfile, CFFI and NumPy.</p>
</div></blockquote>
</li>
<li><p><a class="reference external" href="https://github.com/bastibe/python-soundfile">https://github.com/bastibe/python-soundfile</a></p></li>
</ul>
</section>
<section >
<h3>wavãƒ•ã‚¡ã‚¤ãƒ«ã®ASR</h3>
<pre data-id="wavasr"><code data-trim data-noescape class="python">&gt;&gt;&gt; import soundfile as sf
&gt;&gt;&gt; speech_array, sampling_rate = sf.read(&quot;sample.wav&quot;)
&gt;&gt;&gt; nbests = speech2text(speech_array)
&gt;&gt;&gt; text, tokens, *_ = nbests[0]
&gt;&gt;&gt; print(text)
ä»Šå¹¸ã›</code></pre>
</section>
<section >
<h3>tips: <strong class="command">say</strong> ã‚³ãƒãƒ³ãƒ‰ã§wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œã‚Œã‚‹ï¼</h3>
<pre data-id="tips-say-wav"><code data-trim data-noescape class="shell">$ say -v Kyoko ã„ã¾ã€å¹¸ã›ï¼Ÿ -o sample.wav --data-format=LEF32&#64;16000</code></pre>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&#64;</span></code> ä»¥é™ãŒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆ<strong class="command">man say</strong> å‚ç…§ï¼‰</p></li>
<li><p>ä»Šå›ã®ãƒ¢ãƒ‡ãƒ«ã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ16000Hzã§è¨“ç·´ã•ã‚Œã¦ã„ã‚‹ã®ã§ <strong>åˆã‚ã›ã‚‹</strong></p></li>
</ul>
</section>
</section>
<section>
<section >
<h2>ãƒã‚¤ã‚¯ã‹ã‚‰å…¥åŠ›ã—ãŸéŸ³å£°ã®ASR</h2>
<ul class="simple">
<li><p>ãƒã‚¤ã‚¯ã®æ“ä½œã«ã¯ <code class="docutils literal notranslate"><span class="pre">SpeechRecognition</span></code> ã‚’ä½¿ã„ã¾ã™</p></li>
</ul>
<pre data-id="id39"><code data-trim data-noescape class="python">&gt;&gt;&gt; r = sr.Recognizer()
&gt;&gt;&gt; with sr.Microphone(sample_rate=16_000) as source:
...     audio = r.listen(source)</code></pre>
</section>
<section >
<h3>NumPy arrayã«å¤‰æ›</h3>
<pre data-id="numpy-array"><code data-trim data-noescape class="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; frame_bytes = audio.get_raw_data()
&gt;&gt;&gt; speech_array = np.frombuffer(frame_bytes, dtype=np.int16)</code></pre>
</section>
<section >
<h3>è½ã¨ã—ç©´ï¼šarrayã®dtype</h3>
<ul class="simple">
<li><p>wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’ <code class="docutils literal notranslate"><span class="pre">SoundFile</span></code> ã§èª­ã¿è¾¼ã‚€ã¨ <code class="docutils literal notranslate"><span class="pre">dtype</span></code> ã¯ <strong>float64</strong></p></li>
<li><p>ãƒã‚¤ã‚¯ã‹ã‚‰å…¥åŠ›ã—ãŸéŸ³å£°ã‚’arrayã«å¤‰æ›ã—ãŸã¨ã“ã‚ã€ <code class="docutils literal notranslate"><span class="pre">dtype</span></code> ã¯ <em>int16</em></p></li>
<li><p>è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯ dtype=int16 ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å®ŸåŠ›ã‚’ç™ºæ®ã—ãã‚Œãªã„</p></li>
</ul>
</section>
<section >
<h3>dtypeã‚’int16ã‹ã‚‰float64ã«å¤‰æ›</h3>
<pre data-id="dtypeint16float64"><code data-trim data-noescape class="python">&gt;&gt;&gt; import tempfile
&gt;&gt;&gt; from scipy.io import wavfile
&gt;&gt;&gt; with tempfile.NamedTemporaryFile() as tempf:
...     wavfile.write(tempf.name, audio.sample_rate, speech_array)
...     audio_array, sampling_rate = sf.read(tempf.name)</code></pre>
</section>
<section >
<h3>dtype float64ã®arrayã«ã¤ã„ã¦ASR</h3>
<pre data-id="dtype-float64arrayasr"><code data-trim data-noescape class="python">&gt;&gt;&gt; nbests = speech2text(audio_array)
&gt;&gt;&gt; text, tokens, *_ = nbests[0]
&gt;&gt;&gt; print(text)</code></pre>
</section>
<section >
<h3>ä½œã‚Šè¾¼ã‚“ã ASRã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆ</h3>
<pre data-id="id40"><code data-trim data-noescape class="python">from io import BytesIO

import numpy as np
import soundfile as sf
import speech_recognition as sr
from espnet2.bin.asr_inference import Speech2Text

speech2text = Speech2Text.from_pretrained(
    &quot;kan-bayashi/csj_asr_train_asr_transformer_raw_char_sp_valid.acc.ave&quot;
)

SAMPLING_RATE_HZ = 16_000


def input_from_microphone(recognizer: &quot;sr.Recognizer&quot;) -&gt; &quot;sr.AudioData&quot;:
    with sr.Microphone(sample_rate=SAMPLING_RATE_HZ) as source:
        print(&quot;ãªã«ã‹è©±ã—ã¦ãã ã•ã„&quot;)
        audio = recognizer.listen(source)
        print(&quot;éŸ³å£°ã‚’å–å¾—ã—ã¾ã—ãŸ&quot;)
        return audio


def convert_to_array(audio: &quot;sr.AudioData&quot;) -&gt; &quot;np.array&quot;:
    wav_bytes = audio.get_wav_data()
    wav_stream = BytesIO(wav_bytes)
    audio_array, sampling_rate = sf.read(wav_stream)
    assert sampling_rate == SAMPLING_RATE_HZ
    return audio_array


def recognize_speech(audio_array: &quot;np.array&quot;) -&gt; str:
    nbests = speech2text(audio_array)
    text, tokens, *_ = nbests[0]
    return text


if __name__ == &quot;__main__&quot;:
    r = sr.Recognizer()

    while True:
        audio = input_from_microphone(r)
        array = convert_to_array(audio)
        text = recognize_speech(array)
        print(text)

        character = input(&quot;ã“ã“ã§çµ‚äº†ã™ã‚‹å ´åˆã¯qã€ç¶šã‘ã‚‹å ´åˆã¯Enterã‚’æŠ¼ã—ã¦ãã ã•ã„: &quot;)
        if character.strip().lower() == &quot;q&quot;:
            break
</code></pre>
</section>
<section >
<h3>ã“ã†ã—ã¦è©©éŸ³ v0.0.1 ã¯ä½œã‚Šè¾¼ã¾ã‚ŒãŸ</h3>
<ol class="arabic simple">
<li><p>éŸ³å£°ã‚’èªè­˜ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ï¼ˆASRï¼‰ğŸ™Œ</p></li>
<li><p>ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦å¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œã‚‹</p></li>
<li><p>å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ä¸Šã’ã‚‹ï¼ˆTTSï¼‰ğŸ™Œ</p></li>
</ol>
</section>
</section>
<section>
<section >
<h2>ãƒ†ã‚­ã‚¹ãƒˆã®å‡¦ç†</h2>
<ul class="simple">
<li><p>æœ¬ãƒˆãƒ¼ã‚¯ã§ã¯ã€ã‚ªã‚¦ãƒ è¿”ã—ğŸ¦œ</p></li>
<li><p>ä¸€ç•ªå˜ç´”ãªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†</p></li>
</ul>
<pre data-id="id42"><code data-trim data-noescape class="python">def talk_with_chatbot(sentence: str) -&gt; str:
    return sentence</code></pre>
</section>
<section >
<h3>ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç† future works</h3>
<ul class="simple">
<li><p>è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLPï¼‰ã®ã•ã¾ã–ã¾ãªæŠ€è¡“ãŒä½¿ãˆãã†</p></li>
<li><p>1æ¡ˆã¨ã—ã¦ ChatterBot ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã£ãŸå¿œç­”ï¼ˆé–‹ç™ºä¸­ï¼‰</p></li>
</ul>
</section>
</section>
<section >
<h2>shion.pyã«çµ±åˆ</h2>
<ol class="arabic simple">
<li><p>éŸ³å£°ã‚’èªè­˜ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ï¼ˆASRï¼‰</p></li>
<li><p>ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦å¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œã‚‹ï¼ˆã‚ªã‚¦ãƒ è¿”ã—ï¼‰</p></li>
<li><p>å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ä¸Šã’ã‚‹ï¼ˆTTSï¼‰</p></li>
</ol>
</section>
<section >
<h2>shion.pyã«çµ±åˆ</h2>
<pre data-id="shion-py"><code data-trim data-noescape class="python" data-line-numbers="62,63,64">import warnings
from io import BytesIO

import numpy as np
import sounddevice as sd
import soundfile as sf
import speech_recognition as sr
from espnet2.bin.asr_inference import Speech2Text
from ttslearn.dnntts import DNNTTS

warnings.filterwarnings(&quot;ignore&quot;)

speech2text = Speech2Text.from_pretrained(
    &quot;kan-bayashi/csj_asr_train_asr_transformer_raw_char_sp_valid.acc.ave&quot;
)

SAMPLING_RATE_HZ = 16_000


def input_from_microphone(recognizer: &quot;sr.Recognizer&quot;) -&gt; &quot;sr.AudioData&quot;:
    with sr.Microphone(sample_rate=SAMPLING_RATE_HZ) as source:
        print(&quot;ãªã«ã‹è©±ã—ã¦ãã ã•ã„&quot;)
        audio = recognizer.listen(source)
        print(&quot;éŸ³å£°ã‚’å–å¾—ã—ã¾ã—ãŸ&quot;)
        return audio


def convert_to_array(audio: &quot;sr.AudioData&quot;) -&gt; &quot;np.array&quot;:
    wav_bytes = audio.get_wav_data()
    wav_stream = BytesIO(wav_bytes)
    audio_array, sampling_rate = sf.read(wav_stream)
    assert sampling_rate == SAMPLING_RATE_HZ
    return audio_array


def recognize_speech(audio_array: &quot;np.array&quot;) -&gt; str:
    nbests = speech2text(audio_array)
    text, tokens, *_ = nbests[0]
    return text


def recognize_mircophone_input(recognizer: &quot;sr.Recognizer&quot;) -&gt; str:
    audio = input_from_microphone(recognizer)
    array = convert_to_array(audio)
    return recognize_speech(array)


def process_text(sentence: str) -&gt; str:
    return sentence


dnntts_engine = DNNTTS()


def say(sentence: str):
    audio_array, sampling_rate = dnntts_engine.tts(sentence)
    sd.play(audio_array, sampling_rate)
    sd.wait()


if __name__ == &quot;__main__&quot;:
    r = sr.Recognizer()

    while True:
        text = recognize_mircophone_input(r)
        response = process_text(text)
        say(response)

        character = input(&quot;ã“ã“ã§çµ‚äº†ã™ã‚‹å ´åˆã¯qã€ç¶šã‘ã‚‹å ´åˆã¯Enterã‚’æŠ¼ã—ã¦ãã ã•ã„: &quot;)
        if character.strip().lower() == &quot;q&quot;:
            break
</code></pre>
</section>
<section>
<section >
<h2>ãƒ¡ã‚¤ã‚«ãƒ¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€ŒPythonã§è©©éŸ³ã‚’å®Ÿè£…ã€ã§å­¦ã‚“ã ã“ã¨</h2>
<ul class="simple">
<li><p>æ‰‹æ—©ãå®Ÿè£…</p></li>
<li><p>æ©Ÿæ¢°å­¦ç¿’ã®åˆ©ç”¨ï¼ˆ2ç‚¹ï¼‰</p></li>
</ul>
</section>
<section >
<h3>æ‰‹æ—©ãå®Ÿè£…</h3>
<ul class="simple">
<li><p>TTSï¼ˆéŸ³å£°åˆæˆï¼‰ã¨ASRï¼ˆéŸ³å£°èªè­˜ï¼‰ã‚’ã¾ãšã¯æ‰‹æ—©ãå®Ÿè£…ã™ã‚‹ã“ã¨ã‚’å„ªå…ˆ</p></li>
<li><p><strong>æ‰‹æ—©ã„å®Ÿè£…ã‚’ã¤ãªã„ã§</strong>ã€ã‚·ã‚¹ãƒ†ãƒ ï¼ˆè©©éŸ³ï¼‰ã‚’æ¤œè¨¼ã—ãŸ</p>
<ul>
<li><p>æ›³å…‰å¼¾ ã€é”äººãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã€</p></li>
</ul>
</li>
</ul>
</section>
<section >
<h3>æ©Ÿæ¢°å­¦ç¿’ã®åˆ©ç”¨ 1/2</h3>
<ul class="simple">
<li><p>ASRã® <strong>Web API</strong> ã‚’ä½¿ã£ãŸï¼ˆåˆæ‰‹ï¼‰</p></li>
<li><p>ç§ãŸã¡é–‹ç™ºè€…ã«ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦Web APIã‚’ä½¿ã† <strong>é¸æŠè‚¢</strong> ãŒå¸¸ã«ã‚ã‚‹ï¼</p></li>
</ul>
</section>
<section >
<h3>æ©Ÿæ¢°å­¦ç¿’ã®åˆ©ç”¨ 2/2</h3>
<ul class="simple">
<li><p>TTSã¨ASRã§ã€ <strong>è¨“ç·´æ¸ˆã¿æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«</strong> ã‚’ä½¿ã£ãŸ</p></li>
<li><p>ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span></code> ã™ã‚‹ã‚ˆã†ã«ã€æ©Ÿæ¢°å­¦ç¿’ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã¯è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ <strong>ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ©ç”¨</strong> ã§ãã‚‹ï¼</p></li>
</ul>
</section>
</section>
<section>
<section >
<h2>ã¾ã¨ã‚ğŸŒ¯ Pythonã§å®Ÿè£…ã™ã‚‹ã€ã€ã‚¢ã‚¤ã®æ­Œå£°ã‚’è´ã‹ã›ã¦ã€ã®è©©éŸ³</h2>
<ul class="simple">
<li><p>è©©éŸ³ v0.0.1ã‚’å®šç¾©ã—ã€<code class="file docutils literal notranslate"><span class="pre">shion.py</span></code> ã¨ã—ã¦å®Ÿè£…</p></li>
<li><p>å®Ÿè£…ï¼ˆPythonã§éŸ³å£°èªè­˜ã‚„éŸ³å£°åˆæˆï¼‰ã€å®Ÿè£…ã—ã¦ã®å­¦ã³ã‚’å…±æœ‰</p></li>
</ul>
</section>
<section >
<h3>è©©éŸ³ v0.0.1ã®å®šç¾©</h3>
<ol class="arabic simple">
<li><p>éŸ³å£°ã‚’èªè­˜ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ï¼ˆASRï¼‰</p></li>
<li><p>ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦å¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œã‚‹ï¼ˆã‚ªã‚¦ãƒ è¿”ã—ï¼‰</p></li>
<li><p>å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ä¸Šã’ã‚‹ï¼ˆTTSï¼‰</p></li>
</ol>
</section>
<section >
<h3>ç´å¾—ã§ãã‚‹ã‹ã¯ä½œã£ã¦ã¿ãªã„ã¨åˆ†ã‹ã‚‰ãªã„ã«å¯¾ã—ã¦</h3>
<ul class="simple">
<li><p>åˆæ‰‹ï¼šæ‰‹æ—©ãå®Ÿè£…ã—ã¦ã€ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æ¤œè¨¼ã™ã‚‹ã“ã¨ã‚’å„ªå…ˆ</p></li>
<li><p>æ‰‹æ—©ã„å®Ÿè£…ã‚’ã¤ãªã„ã§ã€ã‚·ã‚¹ãƒ†ãƒ ï¼ˆè©©éŸ³ï¼‰ã‚’æ¤œè¨¼ï¼šæ›³å…‰å¼¾</p></li>
<li><p>ã‚ˆã•ãã†ã ã£ãŸã®ã§ã€åŠ‡ä¸­ã®è©©éŸ³ã«è¿‘ã¥ã‘ã‚‹ä½œã‚Šè¾¼ã¿</p></li>
</ul>
</section>
<section >
<h3>éŸ³å£°èªè­˜ï¼ˆASRï¼‰</h3>
<ul class="simple">
<li><p>ASRã®Web APIã‚’ä½¿ã†ï¼ˆæ‰‹æ—©ã„å®Ÿè£…ï¼‰</p></li>
<li><p>äº‹å‰è¨“ç·´æ¸ˆã¿æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†</p></li>
</ul>
</section>
<section >
<h3>éŸ³å£°åˆæˆï¼ˆTTSï¼‰</h3>
<ul class="simple">
<li><p>OSã®ã‚³ãƒãƒ³ãƒ‰ã‚’å‘¼ã³å‡ºã™ï¼ˆæ‰‹æ—©ã„å®Ÿè£…ï¼‰</p></li>
<li><p>äº‹å‰è¨“ç·´æ¸ˆã¿æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†</p></li>
</ul>
</section>
<section >
<h3>è©©éŸ³ v0.0.1ã‚’å®Ÿè£…ã—ã¦ã®å­¦ã³</h3>
<ul class="simple">
<li><p>ä½œã‚ŠãŸã„ã‚‚ã®ã®ä¸€éƒ¨ã‚’æ©Ÿæ¢°å­¦ç¿’ã®ã‚¿ã‚¹ã‚¯ã¨æ‰ãˆã‚‰ã‚Œã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚‚ã§ãã‚‹</p>
<ul>
<li><p>Web APIã‚’ä½¿ã†</p></li>
<li><p><strong>äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨</strong> ã™ã‚‹</p></li>
</ul>
</li>
</ul>
</section>
<section >
<h3>ã”æ¸…è´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼</h3>
<p>ã‚ãªãŸã®ãƒ¡ã‚¤ã‚«ãƒ¼ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å°ã•ãã¦ã‚‚ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚Œã°å¬‰ã—ã„ã§ã™</p>
</section>
</section>
<section>
<section >
<h2>References</h2>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/ja/3/library/subprocess.html">subprocess --- ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ç®¡ç†</a></p></li>
<li><p><a class="reference external" href="https://github.com/Uberi/speech_recognition/blob/3.8.1/examples/microphone_recognition.py">https://github.com/Uberi/speech_recognition/blob/3.8.1/examples/microphone_recognition.py</a></p></li>
</ul>
</section>
<section >
<h2>References</h2>
<ul class="simple">
<li><p>ã€<a class="reference external" href="https://book.impress.co.jp/books/1120101073">Pythonã§å­¦ã¶éŸ³å£°åˆæˆ</a>ã€</p></li>
<li><p><a class="reference external" href="https://r9y9.github.io/ttslearn/latest/notebooks/ch00_Quick-start.html#DNN%E9%9F%B3%E5%A3%B0%E5%90%88%E6%88%90-(%E7%AC%AC5%E7%AB%A0%E3%83%BB%E7%AC%AC6%E7%AB%A0)">ã€ŒPythonã§å­¦ã¶éŸ³å£°åˆæˆã€ Quick start DNNéŸ³å£°åˆæˆ</a></p></li>
<li><p>sounddevice example: <a class="reference external" href="https://realpython.com/playing-and-recording-sound-python/#python-sounddevice">Playing and Recording Sound in Python â€“ Real Python</a></p></li>
</ul>
</section>
<section >
<h2>References</h2>
<ul class="simple">
<li><p><a class="reference external" href="https://tech.retrieva.jp/entry/2020/12/23/170645">ESPnet ã«ã‚ˆã‚‹éŸ³å£°èªè­˜å…¥é–€ ï½ESPnet Model Zoo ç·¨ï½</a></p></li>
</ul>
</section>
<section >
<h3>Blog outputsï¼ˆåˆæ‰‹ã®å®Ÿè£…ï¼‰</h3>
<ul class="simple">
<li><p>TTS <a class="reference external" href="https://nikkie-ftnext.hatenablog.com/entry/tts-quickly-python-subprocess">ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«èª­ã¿ä¸Šã’ã¦ã‚‚ã‚‰ã„ãŸã„ï¼ã€ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’Pythonã§æ‰‹æ—©ãæ¤œè¨¼ã™ã‚‹</a></p></li>
<li><p>ASR <a class="reference external" href="https://nikkie-ftnext.hatenablog.com/entry/asr-quickly-python-speechrecognition">ã€Œå–‹ã£ãŸå†…å®¹ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«èªè­˜ã—ã¦ã‚‚ã‚‰ã„ãŸã„ï¼ã€ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’Pythonã§æ‰‹æ—©ãæ¤œè¨¼ã™ã‚‹</a></p></li>
</ul>
</section>
<section >
<h3>Blog outputsï¼ˆä½œã‚Šè¾¼ã¿ï¼‰</h3>
<ul class="simple">
<li><p>TTS <a class="reference external" href="https://nikkie-ftnext.hatenablog.com/entry/my-first-shion-python-text-to-speech">Pythonã®èª­ã¿ä¸Šã’ã‚’è´ã‹ã›ã¦</a></p></li>
<li><p>ASR <a class="reference external" href="https://nikkie-ftnext.hatenablog.com/entry/my-first-shion-python-speech-recognition-part1">å£°ã‚’Pythonã«è´ã‹ã›ã¦ï¼ˆå‰ç·¨ï¼šwavãƒ•ã‚¡ã‚¤ãƒ«ã ã¨æ›¸ãèµ·ã“ã›ã‚‹ã®ã«ã€ãƒã‚¤ã‚¯ã®å…¥åŠ›ã¯ã„ã¾ã„ã¡ï¼ï¼Ÿï¼‰</a></p></li>
<li><p>ASR <a class="reference external" href="https://nikkie-ftnext.hatenablog.com/entry/my-first-shion-python-speech-recognition-part2">å£°ã‚’Pythonã«è´ã‹ã›ã¦ï¼ˆå¾Œç·¨ï¼šå¯¾å‡¦ã—ã€ãƒã‚¤ã‚¯ã®éŸ³å£°ã§ã‚‚ã€Œå¤‰ã˜ã‚ƒãªã„ã‚ˆã€ï¼‰</a></p></li>
</ul>
</section>
</section>
<section >
<h2>EOF</h2>
</section>

        </div>
    </div>
    
    <script src="../_static/revealjs4/dist/reveal.js"></script>
    
    
      <script src="../_static/revealjs4/plugin/highlight/highlight.js"></script>
      <script src="../_static/revealjs4/plugin/notes/notes.js"></script>
      
    
    <script>
        var revealjsConfig = new Object();
        Object.assign(revealjsConfig, 
    {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: "none",
        slideNumber: "c/t",
    }
);
        
        
        
          revealjsConfig.plugins = [
            RevealHighlight,RevealNotes,
          ];
        
        // More info https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize(revealjsConfig);
    </script>

  </body>
</html>